# HELP.md â€” What This Project Is and How to Use It

---

## What This Project Does

This is a **knowledge-base chatbot** for a helpdesk product (HWL Agency platform).

The system has two modes:

**1. Offline (ingestion) â€” you run this manually:**
You give it PDF documents (user manuals, how-to guides, FAQ sheets).
It reads them with an LLM, extracts every piece of knowledge into small structured files called "chunks", and builds an index file called `guide.yaml`.

**2. Online (chat) â€” runs as a server:**
When a user asks a question, the system:

1. Looks at `guide.yaml` to find the 2â€“3 most relevant chunks
2. Loads those chunk files from disk
3. Feeds them to the LLM along with the question
4. Returns a structured JSON answer (steps, alerts, choices, etc.)

**The golden rule:** The LLM can ONLY answer from what is in the knowledge base. It cannot make things up from general knowledge. If it's not in a chunk, the bot says it doesn't know.

---

## The Files on Disk

```
troubleshooting-poc/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ guide.yaml          â† The index. Lists every chunk: topic, summary, triggers, file path.
â”‚   â”œâ”€â”€ test-queries.json   â† "Gold Standard" test queries and expected chunks for evaluation
â”‚   â””â”€â”€ chunks/             â† One .md file per knowledge chunk. This is the actual knowledge.
â”‚       â”œâ”€â”€ timecard-invoices-process.md
â”‚       â”œâ”€â”€ email-notification-preferences.md
â”‚       â””â”€â”€ ... (21 chunks currently)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ extract.ts          â† Reads PDFs, calls LLM, writes chunk .md files + guide.yaml
â”‚   â”œâ”€â”€ llm-client.ts       â† All LLM calls â€” circuit breaker, error classification, backoff
â”‚   â”œâ”€â”€ server.ts           â† Hono HTTP API â€” rate limiting, timeout, graceful shutdown
â”‚   â”œâ”€â”€ main.ts             â† Interactive CLI chat (type questions in terminal)
â”‚   â”œâ”€â”€ config.ts           â† Centralized pipeline + server configuration (all env var defaults)
â”‚   â”œâ”€â”€ schemas.ts          â† Zod type definitions for chunks, guide entries, LLM output
â”‚   â”œâ”€â”€ providers.ts        â† Provider registry (Azure / Google / Groq)
â”‚   â”œâ”€â”€ chunker.ts          â† Deterministic heading-based document segmentation engine
â”‚   â”œâ”€â”€ logger.ts           â† Winston logger with AsyncLocalStorage request correlation
â”‚   â”‚
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â”œâ”€â”€ extraction.md      â† System prompt for procedure PDFs
â”‚   â”‚   â”œâ”€â”€ qna-extraction.md  â† System prompt for FAQ/Q&A PDFs
â”‚   â”‚   â”œâ”€â”€ chat-extraction.md â† System prompt for chat log extraction (future)
â”‚   â”‚   â””â”€â”€ chat.md            â† System prompt for answering user questions
â”‚   â”‚
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ ingest.ts          â† Full pipeline orchestrator (extract â†’ validate â†’ relate â†’ rebuild)
â”‚       â”œâ”€â”€ validate.ts        â† Quality check: Zod structure + LLM Clarity/Consistency/Completeness
â”‚       â”œâ”€â”€ relate.ts          â† Find related chunks and wire them together
â”‚       â”œâ”€â”€ rebuild-guide.ts   â† Rebuild guide.yaml from active chunk front matter
â”‚       â”œâ”€â”€ validate-guide.ts  â† Fast Zod-only check on guide.yaml structure
â”‚       â”œâ”€â”€ perf-report.ts     â† Aggregate timing metrics from ingestion reports
â”‚       â”œâ”€â”€ e2e-test.ts        â† Structural regression tests (no LLM, runs in seconds)
â”‚       â”œâ”€â”€ eval-retrieval.ts  â† Retrieval accuracy evaluation (requires test-queries.json)
â”‚       â”œâ”€â”€ source-manifest.ts â† Track which PDF produced which chunks
â”‚       â”œâ”€â”€ chunk-debug.ts     â† PDF segmentation preview (no LLM)
â”‚       â””â”€â”€ delete.ts          â† Remove a chunk from the KB and resync guide.yaml
â”‚
â”œâ”€â”€ source-manifest.json    â† Created at runtime. Maps PDF â†’ chunk_ids + hash
â”œâ”€â”€ package.json            â† All runnable commands are here
â”œâ”€â”€ .env                    â† Your API keys (copy from .env.example)
â”œâ”€â”€ .env.example            â† All supported environment variables with defaults
â””â”€â”€ HELP.md                 â† This file
```

---

## All Commands â€” What to Run and What to Expect

### 1. `bun run ingest <pdf-file-or-directory>`

**What it does:** Full pipeline in one command. Runs all 4 steps below in order.
**When to use:** Every time you add new PDFs to the knowledge base.

**Flags:**

- `--type=qna`: If the PDF you are ingesting is an FAQ layout instead of a User Manual, pass this flag so it alters the underlying prompt for better extraction quality.

```bash
bun run ingest ./my-manual.pdf
bun run ingest --type=qna ./faq.pdf # Use for Q&A documents
bun run ingest ./docs/             # all PDFs in a folder
bun run ingest a.pdf b.pdf         # multiple files
```

**Expected output:**

```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  ğŸš€ HWL Knowledge Base â€” Ingestion Orchestrator
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‹ Sources queued for ingestion:
   â€¢ my-manual.pdf
   Total: 1 PDF(s)

[1/4] Extract â€” PDF â†’ chunks + guide.yaml
  âœ“ Created: some-topic.md
  âœ“ Created: another-topic.md

[2/4] Validate â€” Zod structural + LLM quality gates
  âœ… some-topic.md â€” structure OK
  âœ… another-topic.md â€” structure OK

[3/4] Relate â€” populate related_chunks across KB
  Relating some-topic... âœ“ [another-topic]

[4/4] Rebuild â€” regenerate guide.yaml from chunk front matter

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  âœ… Ingestion Complete
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
  Started at:    2026-02-24T...
  Total time:    45.2s
  Sources:       1 PDF(s)
  Active chunks: 23

  Step Results:
    âœ… extract   42.1s
    âœ… validate   8.3s
    âœ… relate     3.1s
    âœ… rebuild    0.2s

  Knowledge base is ready. Start the server with:
    bun run server
```

---

### 2. `bun run extract [--type=qna] <pdf-file-or-directory>`

**What it does:** Step 1 only. Reads the PDF, calls the LLM to extract knowledge chunks, writes `.md` files to `data/chunks/`. Updates `source-manifest.json`.
**When to use:** If you only want extraction without validation (rare). Passing `--type=qna` uses a specialized prompt for Q&A documents instead of standard procedures.

```bash
bun run extract ./my-manual.pdf
bun run extract --type=qna ./my-faq.pdf
```

**Expected output:**

```
ğŸš€ Starting extraction for 1 source(s)...

â”â”â” [1/1] my-manual.pdf â”â”â”

ğŸ“„ Reading PDF: /path/to/my-manual.pdf
  â†³ PDF size: 420.3 KB

â±  LLM extraction [my-manual.pdf]: 38.2s
  âœ“ Created: some-topic.md
    Topic:   Timecards
    Summary: How to submit a timecard in HWL Agency
    Triggers: 3
    Images:  2
    Conditions: false

ğŸ“‹ source-manifest.json updated

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“Š Extraction Summary
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
   Sources processed : 1
   Chunks created    : 3
   Chunks updated    : 0
   Sources failed    : 0
   Total time        : 38.4s
   Output directory  : /path/to/data/chunks
   Guide index       : data/guide.yaml
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Next steps:
  1. Validate chunks:  bun run validate
  2. Link related:     bun run relate
  3. Rebuild index:    bun run rebuild
  â€” or run all steps: bun run ingest <sources>
```

---

### 3. `bun run validate`

**What it does:** Two-phase quality check on all active chunks.

- **Phase 1 (instant, no LLM):** Checks that each `.md` file has valid YAML front matter, all required fields (`chunk_id`, `topic`, `summary`, `triggers`, etc.), and the required markdown sections (`## Context`, `## Response`, `## Escalation`). Marks bad chunks `status: review` immediately â€” no LLM call wasted.
- **Phase 2 (LLM):** Checks **Clarity**, **Consistency**, and **Completeness** of each structurally valid chunk. Uses `callLlmWithRetry` â€” one automatic retry on transient errors before marking for review.

```bash
bun run validate
```

**Expected output:**

```
ğŸ” Validating chunks (Phase 1: Structural Â· Phase 2: LLM Quality)...

Phase 1 â€” Zod structural check: front-matter schema + required sections
Phase 2 â€” LLM quality gates:    Clarity Â· Consistency Â· Completeness

â”â”â” Phase 1: Structural Validation â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

  âœ… timecard-invoices-process.md â€” structure OK
  âœ… email-notification-preferences.md â€” structure OK
  ...

  Structural: 21 passed, 0 failed

â”â”â” Phase 2: LLM Quality Gates â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“‚ Sending 21 structurally valid active chunk(s) to LLM...

  âœ… timecard-invoices-process        Clarity âœ“  Consistency âœ“  Completeness âœ“
  âœ… email-notification-preferences   Clarity âœ“  Consistency âœ“  Completeness âœ“
  ...

âœ… Validation complete â€” 21 passed, 0 failed
```

**If a chunk fails Phase 1:**

```
  âŒ some-chunk.md â€” structural FAIL
       â€¢ front-matter.summary: Required
       â€¢ Missing required markdown section: "## Response"
       â†’ Marked as status: review (structural failure)
```

---

### 4. `bun run relate`

**What it does:** Asks the LLM to find which chunks are related to each other. Writes the relationships into each chunk's `related_chunks` front matter field. This helps the chat system find relevant context even when the exact match isn't obvious.

```bash
bun run relate
```

**Expected output:**

```
ğŸ”— Running post-aggregation related chunks pass...

ğŸ“‚ Processing 21 active chunk(s)...

  Relating timecard-invoices-process... âœ“ [expense-invoices-process]
  Relating email-notification-preferences... âœ“ [update-email-preferences-default-selection, update-email-preferences-manual-selection]
  ...

âœ… Related chunks written for 21 chunk(s)

ğŸ”¨ Rebuilding guide.yaml...
âœ… Done.
```

---

### 5. `bun run rebuild`

**What it does:** Reads every `.md` file in `data/chunks/`, extracts the YAML front matter from each **active** chunk, and regenerates `guide.yaml` from scratch for retrieval. It intentionally ignores chunks marked as "review" or "deprecated". Use this any time you edit chunk files manually or after deletions.

```bash
bun run rebuild
```

**Expected output:**

```
ğŸ”¨ Rebuilding guide.yaml from 21 active chunk(s)...
âœ… guide.yaml rebuilt.
```

---

### 6. `bun run validate-guide`

**What it does:** Fast structural check â€” reads `guide.yaml` and validates every entry against the GuideEntry schema using Zod. No LLM calls. Runs in under 1 second.

```bash
bun run validate-guide
```

**Expected output (all pass):**

```
ğŸ” Validating guide.yaml against GuideEntrySchema...

ğŸ“‚ Found 21 guide.yaml entry/entries

  âœ… candidate-status-column-buttons
  âœ… dashboard-detailed-view
  âœ… email-notification-preferences
  ...

ğŸ“Š guide.yaml Validation Summary
   Entries checked: 21
   Passed:          21
   Failed:          0

âœ… All guide.yaml entries are structurally valid.
```

---

### 7. `bun run perf-report`

**What it does:** Reads structured ingestion reports from `data/reports/` and aggregates metrics, providing an average duration summary for each pipeline step across runs.

```bash
bun run perf-report
```

**Expected output:**

```
ğŸ“Š HWL Ingestion Performance Report
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  Processed Runs:  1
  Total Sources:   1
  Avg Run Time:    116.7s

  Average Time per Step:
    â€¢ extract         100.9s
    â€¢ validate        10.1s
...
```

---

### 8. `bun run e2e-test` (also `bun run test`)

**What it does:** Full structural regression test. Checks that:

- `guide.yaml` exists and has entries
- Every guide entry has a matching `.md` file on disk
- Every `.md` file has a guide entry
- Every chunk passes the front-matter Zod schema
- Every chunk has `## Context`, `## Response`, `## Escalation` sections
- No chunks have the old `chunk_id:` prefix bug in `related_chunks`
- Every guide.yaml entry passes GuideEntrySchema

No LLM calls. Runs in under 3 seconds.

```bash
bun run e2e-test
```

**Expected output (healthy KB):**

```
ğŸ§ª HWL Knowledge Base â€” End-to-End Structural Tests

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“ Test: File System Integrity
  âœ… guide.yaml exists
  âœ… data/chunks/ directory exists

ğŸ“‹ Test: guide.yaml â†” Filesystem Consistency
  âœ… guide.yaml has at least 1 entry
  âœ… data/chunks/ has at least 1 .md file
  âœ… guide entry 'timecard-invoices-process' has .md file
  ...

ğŸ” Test: Chunk Front-Matter Schema Validation
  âœ… timecard-invoices-process.md front-matter schema
  ...

ğŸ“„ Test: Required Markdown Sections
  âœ… timecard-invoices-process.md has ## Context
  âœ… timecard-invoices-process.md has ## Response
  âœ… timecard-invoices-process.md has ## Escalation
  ...

ğŸ”— Test: related_chunks Format Normalisation (GAP-D1-05)
  âœ… timecard-invoices-process.md has no 'chunk_id:' prefix in related_chunks
  ...

ğŸ“Š E2E Test Results
   Total:   172
   Passed:  172
   Failed:  0

âœ… All structural invariants pass.
```

---

### 9. `bun run server`

**What it does:** Starts the HTTP API server on port 3000 (or `PORT` env var).

```bash
bun run server
```

**Expected output:**

```
ğŸš€ Server ready â€” 21 chunks in guide.yaml

ğŸŒ Listening on http://localhost:3000
ğŸ“ Logging to data/logs/requests.ndjson
ğŸ”’ CORS origin: http://localhost:5173
â±  Request timeout: 120s
ğŸš¦ Rate limit: 20 req / 60s per session
```

**Routes:**

```
GET  /api/health   â€” server status and chunk count
GET  /api/chunks   â€” list all chunks from guide.yaml
POST /api/chat     â€” question-answering endpoint
```

**Test it:**

```bash
# Health check
curl http://localhost:3000/api/health

# Ask a question
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "How do I submit a timecard?", "sessionId": "test123"}'
```

**Chat response shape:**

```json
{
  "response": {
    "type": "steps",
    "data": {
      "title": "How to submit a timecard",
      "steps": [{ "title": "Step 1", "body": "..." }]
    }
  },
  "contextChunks": [
    {
      "chunk_id": "timecard-invoices-process-a1b2c3d4",
      "topic": "Timecard Submission",
      "file": "HWL Agency Manual.pdf"
    }
  ]
}
```

The `X-Request-Id` response header carries a short ID that correlates all server logs for this request.

---

### 10. `bun run chat`

**What it does:** Interactive terminal chat. Type questions, get answers. No server needed.

**Flags:**

- `--debug`: Activates "Developer Mode". Before rendering the final answer, it prints out the precise `chunk_id`s, `topic`s, and chunk contents that the AI successfully retrieved during its search phase. Critical for debugging retrieval failures.

```bash
bun run chat
bun run chat --debug
```

**Expected output (Standard):**

```
ğŸ’¬ HWL Assistant â€” type your question (or 'exit')

You: How do I reset my password?
Assistant: [structured answer from knowledge base]

You: exit
```

**Expected output (with `--debug` flag):**

```
You: How do I reset my password?
Assistant:
ğŸ” Calling LLM...
ğŸ” Step 1 â€” Retrieval: finding relevant chunks from guide...

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ” [DEBUG] EVIDENCE: The AI is reading the following chunks
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ Chunk 1 of 2
   ID:      hwl-agency-password-reset
   Topic:   Password Reset Procedure
   ...
```

---

### 11. `bun run delete`

**What it does:** Removes a chunk by chunk_id from both `data/chunks/` and `guide.yaml`.

```bash
bun run delete timecard-invoices-process
```

**Expected output:**

```
ğŸ—‘ï¸  Deleting chunk: timecard-invoices-process
  âœ… Removed: data/chunks/timecard-invoices-process.md
  âœ… Removed from guide.yaml
```

---

### 12. `bun run score`

**What it does:** Runs the automated retrieval accuracy evaluation script (`eval-retrieval.ts`). It loads the "Gold Standard" list of test questions from `data/test-queries.json` and checks if the AI's retrieval engine successfully pulls the expected chunk ID for every question.

**When to use:** Crucial for regression testing. Run this before client demos or whenever you drastically alter the chunk triggers/summaries to ensure you aren't hurting overall search accuracy.

```bash
bun run score
```

**Expected output:**

```
ğŸ“Š Retrieval Accuracy Score: 100% (5/5)

Full details saved to: data/reports/eval-report-2026-02-24T...
```

---

## Design Principles

1. **The LLM decides the knowledge, not the developer.** You give it a PDF and it extracts what it thinks is important. You don't write the chunks by hand.

2. **`guide.yaml` is the index, `.md` files are the truth.** `guide.yaml` is generated from the `.md` files â€” so if they disagree, run `bun run rebuild` to fix it.

3. **Chunks are self-contained.** A user reading one chunk must be able to understand it completely without reading any other chunk. This is enforced by the extraction prompt.

4. **The system only knows what's in the PDFs.** If a user asks about something not in any chunk, the bot returns an escalation response. It never invents an answer.

5. **Q&A format PDFs are different from procedure PDFs.** Procedure PDFs = how-to guides and step-by-step instructions. Q&A PDFs = FAQ documents. Use `--type=qna` during extraction to apply the specialized prompt.

6. **Reliability is layered.** Every LLM call goes through the circuit breaker â†’ classified error â†’ exponential backoff + jitter. File reads in pipeline loops are individually guarded. The server rate-limits, enforces a body size cap, and times out hangs.

---

## Quick Start (from zero)

```bash
# 1. Copy env file and fill in your API key
cp .env.example .env
# Edit .env: set AI_PROVIDER=google (or azure/groq) and the matching API key

# 2. Install dependencies
bun install

# 3. Ingest a PDF
bun run ingest ./your-manual.pdf

# 4. Verify everything is healthy
bun run e2e-test

# 5. Start the server
bun run server

# 6. Test a question
curl -X POST http://localhost:3000/api/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "How do I submit a timecard?", "sessionId": "s1"}'
```
