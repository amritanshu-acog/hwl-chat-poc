/**
 * src/scripts/ingest.ts  â€” GAP-D1-02
 *
 * End-to-end ingestion orchestrator.
 *
 * Runs: extract â†’ validate â†’ relate â†’ rebuild in the correct sequence
 * with full error propagation, per-step timing, and a structured final report.
 *
 * Usage:
 *   bun run ingest <file.pdf>
 *   bun run ingest ./docs/
 *   bun run ingest a.pdf b.pdf c.pdf
 */

import { execFileSync } from "child_process";
import { resolve, extname, basename } from "path";
import { stat, readdir, readFile, writeFile, mkdir } from "fs/promises";
import { join } from "path";
import { CONFIG } from "../config.js";
import { logger } from "../logger.js";

// â”€â”€â”€ Types â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

interface StepResult {
  step: string;
  success: boolean;
  durationMs: number;
  output: string;
  error?: string;
}

interface IngestReport {
  startedAt: string;
  sources: string[];
  steps: StepResult[];
  chunksInKB: number;
  totalDurationMs: number;
  success: boolean;
}

// â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function banner(text: string): void {
  logger.info(text);
}

function stepHeader(step: string, index: number, total: number): void {
  logger.info(`Step [${index}/${total}]: ${step}`);
}

/**
 * Run a bun script synchronously.
 * Uses execFileSync (NOT execSync) so args are passed as an array â€”
 * this avoids shell-splitting paths that contain spaces.
 */
function runStep(label: string, command: string, args: string[]): StepResult {
  const start = Date.now();
  let error: string | undefined;
  let success = false;

  try {
    execFileSync(command, args, {
      cwd: process.cwd(),
      encoding: "utf-8",
      // inherit: output streams directly to terminal so user sees progress live
      stdio: "inherit",
    });
    success = true;
  } catch (err: any) {
    // execFileSync throws on non-zero exit â€” extract the error message
    error = err?.message ?? String(err);
    success = false;
  }

  return {
    step: label,
    success,
    durationMs: Date.now() - start,
    output: "", // stdio:inherit means output went directly to terminal
    error,
  };
}

/** Count active chunks in guide.yaml */
async function countActiveChunks(): Promise<number> {
  try {
    const guide = await readFile(CONFIG.paths.guide, "utf-8");
    return (guide.match(/status:\s*active/g) ?? []).length;
  } catch {
    return 0;
  }
}

/** Resolve PDF sources from CLI args (files or directories) */
async function resolveSources(args: string[]): Promise<string[]> {
  const sources: string[] = [];
  for (const arg of args) {
    const resolved = resolve(arg);
    let info;
    try {
      info = await stat(resolved);
    } catch {
      logger.warn("Path not found", { path: arg });
      continue;
    }

    if (info.isDirectory()) {
      const entries = await readdir(resolved);
      const pdfs = entries
        .filter((f) => extname(f).toLowerCase() === ".pdf")
        .sort()
        .map((f) => join(resolved, f));

      if (pdfs.length === 0) {
        logger.warn("No PDFs found in directory", { directory: resolved });
      }
      sources.push(...pdfs);
    } else if (info.isFile()) {
      if (extname(resolved).toLowerCase() !== ".pdf") {
        logger.warn("Skipping non-PDF file", { path: arg });
      } else {
        sources.push(resolved);
      }
    }
  }
  return sources;
}

// â”€â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

async function main(): Promise<void> {
  const args = process.argv.slice(2);

  if (args.length === 0) {
    console.log(`
Usage:
  bun run ingest [--type=<type>] <source> [source2] ...

Extraction Types:
  --type=procedure  (default) Step-by-step how-to guides and workflows
  --type=qna        FAQ / Q&A documents
  --type=chat       âš ï¸  FUTURE â€” HubSpot chat conversation exports (stub only)

Recommended Input Directories:
  ./docs/procedure/   Drop procedure PDFs here â†’ bun run ingest --type=procedure ./docs/procedure/
  ./docs/qna/         Drop FAQ PDFs here       â†’ bun run ingest --type=qna ./docs/qna/
  ./docs/chat/        Drop chat exports here   â†’ bun run ingest --type=chat ./docs/chat/  (future)

Sources:
  â€¢ Single PDF file:  bun run ingest ./manual.pdf
  â€¢ Multiple PDFs:    bun run ingest a.pdf b.pdf
  â€¢ Whole directory:  bun run ingest ./docs/procedure/
  â€¢ Mixed:           bun run ingest --type=qna faq.pdf extra.pdf

What this does (in order):
  1. extract  â€” PDF â†’ chunk .md files + guide.yaml
  2. validate â€” LLM quality gates (Clarity, Consistency, Completeness)
  3. relate   â€” Populate related_chunks across all active chunks
  4. rebuild  â€” Regenerate guide.yaml from chunk front matter (source of truth)
`);
    process.exit(1);
  }

  const flags: string[] = [];
  const sourceArgs: string[] = [];
  for (const arg of args) {
    if (arg.startsWith("--")) {
      flags.push(arg);
    } else {
      sourceArgs.push(arg);
    }
  }

  const sources = await resolveSources(sourceArgs);

  if (sources.length === 0) {
    logger.error("No valid PDF sources found. Aborting.");
    process.exit(1);
  }

  logger.info("Ingestion orchestrator started");
  logger.info("Sources queued for ingestion", {
    sources: sources.map((s) => basename(s)),
    total: sources.length,
  });

  const startedAt = new Date().toISOString();
  const totalStart = Date.now();
  const steps: StepResult[] = [];

  // â”€â”€ Step 1: Extract â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  stepHeader("Extract â€” PDF â†’ chunks + guide.yaml", 1, 4);
  const extractResult = runStep("extract", "bun", [
    "run",
    "extract",
    ...flags,
    ...sources,
  ]);
  steps.push(extractResult);

  if (!extractResult.success) {
    logger.error("âŒ Extraction failed:\n", extractResult.error);
    logger.error(
      "\nâ›” Aborting pipeline â€” no point validating failed extraction.",
    );
    printReport({
      startedAt,
      sources,
      steps,
      chunksInKB: 0,
      totalDurationMs: Date.now() - totalStart,
      success: false,
    });
    process.exit(1);
  }
  logger.info(`âœ… Extract complete (${extractResult.durationMs}ms)`);

  // â”€â”€ Step 2: Validate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  stepHeader("Validate â€” Zod structural + LLM quality gates", 2, 4);
  const validateResult = runStep("validate", "bun", ["run", "validate"]);
  steps.push(validateResult);

  if (!validateResult.success) {
    logger.warn(
      "âš ï¸  Validation step encountered errors:\n",
      validateResult.error,
    );
    logger.warn(
      "   Continuing pipeline â€” failed chunks are marked 'review' and excluded from retrieval.",
    );
  } else {
    logger.info(`âœ… Validate complete (${validateResult.durationMs}ms)`);
  }

  // â”€â”€ Step 3: Relate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  stepHeader("Relate â€” populate related_chunks across KB", 3, 4);
  const relateResult = runStep("relate", "bun", ["run", "relate"]);
  steps.push(relateResult);

  if (!relateResult.success) {
    logger.warn("âš ï¸  Relate step failed:\n", relateResult.error);
    logger.warn("   Continuing â€” related_chunks may be empty for new chunks.");
  } else {
    logger.info(`âœ… Relate complete (${relateResult.durationMs}ms)`);
  }

  // â”€â”€ Step 4: Rebuild â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  stepHeader("Rebuild â€” regenerate guide.yaml from chunk front matter", 4, 4);
  const rebuildResult = runStep("rebuild", "bun", ["run", "rebuild"]);
  steps.push(rebuildResult);

  if (!rebuildResult.success) {
    logger.error("âŒ Rebuild failed:\n", rebuildResult.error);
    // Rebuild failure is critical â€” guide.yaml may be stale
    printReport({
      startedAt,
      sources,
      steps,
      chunksInKB: 0,
      totalDurationMs: Date.now() - totalStart,
      success: false,
    });
    process.exit(1);
  }
  logger.info(`âœ… Rebuild complete (${rebuildResult.durationMs}ms)`);

  // â”€â”€ Final report â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const chunksInKB = await countActiveChunks();
  const report: IngestReport = {
    startedAt,
    sources,
    steps,
    chunksInKB,
    totalDurationMs: Date.now() - totalStart,
    success: steps.every((s) => s.success),
  };

  printReport(report);

  // â”€â”€ Save structured report (Task 15: Error reporting hook) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  try {
    const reportsDir = CONFIG.paths.reports;
    await mkdir(reportsDir, { recursive: true });
    const timestamp = startedAt.replace(/[:.]/g, "-");
    const reportPath = join(reportsDir, `ingest-${timestamp}.json`);
    await writeFile(reportPath, JSON.stringify(report, null, 2), "utf-8");
    logger.info(`ğŸ“ Structured report saved: ${reportPath}`);
  } catch (err) {
    logger.error("âš ï¸  Failed to save structured report:", err);
  }

  process.exit(report.success ? 0 : 1);
}

// â”€â”€â”€ Report printer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function printReport(report: IngestReport): void {
  banner(
    report.success
      ? "âœ… Ingestion Complete"
      : "âš ï¸  Ingestion Completed with Errors",
  );

  logger.info(`  Started at:    ${report.startedAt}`);
  logger.info(
    `  Total time:    ${(report.totalDurationMs / 1000).toFixed(1)}s`,
  );
  logger.info(`  Sources:       ${report.sources.length} PDF(s)`);
  logger.info(`  Active chunks: ${report.chunksInKB}`);
  logger.info("");

  logger.info("  Step Results:");
  const maxLabel = Math.max(...report.steps.map((s) => s.step.length));
  for (const step of report.steps) {
    const icon = step.success ? "âœ…" : "âŒ";
    const pad = " ".repeat(maxLabel - step.step.length);
    logger.info(
      `    ${icon} ${step.step}${pad}  ${(step.durationMs / 1000).toFixed(1)}s`,
    );
    if (!step.success && step.error) {
      const preview = step.error.trim().split("\n")[0];
      logger.warn(`Step error preview: ${preview}`, { step: step.step });
    }
  }

  if (report.success) {
    logger.info(
      "Knowledge base is ready. Start the server with: bun run server",
    );
  } else {
    logger.warn(
      "Review errors above. Fix failing chunks, then re-run: bun run ingest <sources>",
    );
  }
}

main().catch((err) => {
  logger.error("Orchestrator failed", {
    error: err instanceof Error ? err.message : String(err),
  });
  process.exit(1);
});
